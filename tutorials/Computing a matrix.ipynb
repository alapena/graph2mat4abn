{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec156d6-650e-41e1-823a-e24478c481d9",
   "metadata": {},
   "source": [
    "# Computing an equivariant matrix\n",
    "\n",
    "In this notebook we guide you through your first steps on using `graph2mat` to compute an equivariant matrix. \n",
    "\n",
    "Our goal will be to **compute a matrix from the coordinates of some points in space**.\n",
    "\n",
    "In particular we will use a version of `Graph2Mat` that is designed to deal with `e3nn`'s conventions: `E3nnGraph2Mat`.\n",
    "\n",
    "We will have to follow the next steps:\n",
    "\n",
    "1. **Create a function** to compute the matrix.\n",
    "2. **Get the coordinates** of the system .\n",
    "3. **Preprocess** the system's data to make it usable by the function.\n",
    "4. **Generate some input** for the function.\n",
    "5. **Call the function**.\n",
    "6. **Postprocess** the output to get the matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84a1300b-d3c0-4fd1-83a6-7b3c2602c824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# So that we can plot sisl geometries\n",
    "import sisl.viz\n",
    "\n",
    "from e3nn import o3\n",
    "\n",
    "from graph2mat import (\n",
    "    PointBasis,\n",
    "    BasisTableWithEdges,\n",
    "    BasisConfiguration,\n",
    "    MatrixDataProcessor,\n",
    ")\n",
    "\n",
    "from graph2mat.bindings.torch import TorchBasisMatrixData\n",
    "from graph2mat.bindings.e3nn import E3nnGraph2Mat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1a578c-7a91-4656-9a0b-5dcf7c62820e",
   "metadata": {},
   "source": [
    "Create a function to generate matrices\n",
    "-----\n",
    "\n",
    "In this section, we focus on the things you need to create a function to compute equivariant matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5feae420-bba5-4982-a87e-934820d2e118",
   "metadata": {},
   "source": [
    "There are three things that you need to know about your problem:\n",
    "\n",
    "1. **The basis functions**. Each point will have a set of basis functions $\\phi_\\mu$ that look something like $\\phi_\\mu = R(r)Y_{\\ell}^m(\\theta, \\varphi)$, where $Y_\\ell^m$ are the *spherical harmonics*. Most likely, you will have points of different types, and each type will have a given set of basis functions. E.g. different order ($\\ell$) of spherical harmonics, or different number of sets for a given $\\ell$. In any case, **you must know beforehand all the unique basis sets** that you will use in your problem.\n",
    "2. **The shape of the inputs**. What are the inputs from which you will compute the matrix? Are they scalars, are they vectors, higher order spherical harmonics...? How many of them will you have? This information is all condensed into an *irreps* specification that you will pass to the function creation.\n",
    "3. **The symmetries of your output matrix**. Is it symmetric? Is each *point-point* block symmetric?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034d3cdb-eaad-4299-9fca-201ab17a545e",
   "metadata": {},
   "source": [
    "#### Define your basis\n",
    "\n",
    "The first thing to do is to understand which basis functions will you face in your problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4cade6-5886-4ffc-9d96-49857dfab599",
   "metadata": {},
   "source": [
    "Let's say that we know that all the systems that we will deal with have two different types of points:\n",
    "\n",
    "- **A**, which has only an $\\ell=0$ basis function with a range of `2`.\n",
    "- **B**, which has two $\\ell=0$ basis function and a set of $\\ell=1$ basis functions with a range of `5`.\n",
    "\n",
    "We need to create a ``PointBasis`` for each of the types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "95487708-91a8-4166-8954-7145f576065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "point_1 = PointBasis(\"A\", R=-1, basis=\"0e\", basis_convention=\"spherical\")  # \"0e\"\n",
    "point_2 = PointBasis(\"B\", R=-1, basis=\"2x0e + 1o\", basis_convention=\"spherical\")\n",
    "\n",
    "basis = [point_1, point_2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8353a263-74c8-4c70-88de-af80519d2a20",
   "metadata": {},
   "source": [
    "For the basis specification, we have decided to follow `e3nn`'s [string specification for irreps](https://docs.e3nn.org/en/stable/api/o3/o3_irreps.html#e3nn.o3.Irreps), where in practical terms:\n",
    "\n",
    "- `0e` means spherical harmonics for $\\ell=0$.\n",
    "- `1o` means spherical harmonics for $\\ell=1$\n",
    "- `2x` means 2 sets of the given spherical harmonics.\n",
    "- `+` just merges the multiple spherical harmonics together.\n",
    "\n",
    "`PointBasis`'s basis specification can also accept a list like `[2, 1]`, meaning 2 $\\ell=0$ spherical harmonics and 1 set of $\\ell=1$ spherical harmonics.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The basis definition is not specific to using e3nn's bindings through `E3nnGraph2Mat`, we would have defined the basis like this\n",
    "even if we were using the raw `Graph2Mat`.\n",
    "\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "\n",
    "Warning on basis convention\n",
    "\n",
    "Make sure that the `basis_convention` that you pass to `PointBasis` is actually the convention used by your target matrix! Otherwise **the equivariance of the generated matrix will be completely wrong**. In that case, if you are creating a model to learn matrices, the model will be unable to learn anything. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6c1083-0ddb-41d1-aa10-80fb5b93f550",
   "metadata": {},
   "source": [
    "#### Define the shape of the inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669cc4f5-ea73-4c57-aafd-014172cfb03a",
   "metadata": {},
   "source": [
    "The function expects a **point-wise input**. That is, one input for each point.\n",
    "\n",
    "For `e3nn` operations, you need to know what is the shape of this input and what each number means. You must ask yourself two questions:\n",
    "\n",
    "- What kind of inputs will you receive? Scalars, vectors, higher order spherical harmonics...?\n",
    "- How many of them will you receive?\n",
    "\n",
    "In this example, we are going to keep it simple and say that **for each node we will pass one scalar and one vector**. We just need to define an `e3nn` `Irreps` object with the appropiate *irreps*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5f44a2dc-36f8-46a2-a6fd-289dd8739733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The irreps of the node features that we will input into the model\n",
    "# One scalar (0e) and one vector (1o)\n",
    "node_feats_irreps = o3.Irreps(\"0e + 2x1o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b8e747-e53d-458e-b196-15722233e99d",
   "metadata": {},
   "source": [
    "#### Initialize the module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c4aa8b-5311-4b83-8a66-7a005be5f17f",
   "metadata": {},
   "source": [
    "Armed with all the information about our inputs and outputs, we can finally **create our matrix generating function**.\n",
    "\n",
    "It is now that we will be able to initialize an `E3nnGraph2Mat` function. For the simplest usage, we just need to pass:\n",
    "\n",
    "- `unique_basis`: The list of `PointBasis` that the function should be able to deal with.\n",
    "- `irreps`: A dictionary containing the irreps for all relevant features that the model will deal with. In this case we will just use node features, so we just need to pass `node_feats_irreps`.\n",
    "- `symmetric`: Whether our target matrices are symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d6dc285e-d5f0-43ea-b23f-7f54d0b47a8c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n",
      "/home/angel/miniconda3/envs/graph2mat/lib/python3.12/site-packages/torch/jit/_check.py:178: UserWarning:\n",
      "\n",
      "The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = E3nnGraph2Mat(\n",
    "    unique_basis=basis,\n",
    "    irreps=dict(node_feats_irreps=node_feats_irreps),\n",
    "    symmetric=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ffc03-73b2-49a4-a59e-604cab236075",
   "metadata": {},
   "source": [
    "We now have our first matrix model!\n",
    "\n",
    "We can explore it. Let's use its `summary` property:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c4fd37d6-ecd3-447d-9f7d-6571b1e42a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing nodes: None\n",
      "Preprocessing edges: None\n",
      "Node operations:\n",
      " (A)  E3nnSimpleNodeBlock: (1x0e) x (1x0e) -> 1x0e\n",
      " (B)  E3nnSimpleNodeBlock: (2x0e+1x1o) x (2x0e+1x1o) -> 4x0e+2x1o+1x2e\n",
      "Edge operations:\n",
      " (A, A) [XY = YX.T] E3nnSimpleEdgeBlock: (1x0e) x (1x0e) -> 1x0e.\n",
      " (A, B) E3nnSimpleEdgeBlock: (1x0e) x (2x0e+1x1o) -> 2x0e+1x1o.\n",
      " (B, B) [XY = YX.T] E3nnSimpleEdgeBlock: (2x0e+1x1o) x (2x0e+1x1o) -> 5x0e+4x1o+1x1e+1x2e.\n"
     ]
    }
   ],
   "source": [
    "print(model.summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22175734-7b93-4de9-947e-eb784c215b4f",
   "metadata": {},
   "source": [
    "You can see that the module created 5 different operations:\n",
    "\n",
    "- **Two node operations**: They will compute the blocks corresponding to interactions within the same point.\n",
    "- **Three edge operations**: They will compute the blocks corresponding to interactions between different points.\n",
    "\n",
    "Note that the summary also prints the irreps of each point basis involved and the output needed to generate the corresponding block. \n",
    "\n",
    "It also indicates with `[XY = YX.T]` if the operation returns the transpose block when you commute factors.\n",
    "\n",
    "However, this short summary doesn't tell us exactly what operations are performed. Since `E3nnGraph2Mat` is a `torch` module, its representation will show us what is exactly the anatomy of the operation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db5a0641-a3f4-455e-8c43-06c927bcd376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "E3nnGraph2Mat(\n",
       "  (self_interactions): ModuleList(\n",
       "    (0): E3nnIrrepsMatrixBlock(\n",
       "      (operation): E3nnSimpleNodeBlock(\n",
       "        (tsq): TensorSquare(1x0e+2x1o -> 1x0e | 4 paths | 4 weights)\n",
       "      )\n",
       "    )\n",
       "    (1): E3nnIrrepsMatrixBlock(\n",
       "      (operation): E3nnSimpleNodeBlock(\n",
       "        (tsq): TensorSquare(1x0e+2x1o -> 4x0e+2x1o+1x2e | 23 paths | 23 weights)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (interactions): ModuleDict(\n",
       "    ((0, 0, 0)): E3nnIrrepsMatrixBlock(\n",
       "      (operation): E3nnSimpleEdgeBlock(\n",
       "        (tensor_products): ModuleList(\n",
       "          (0): FullyConnectedTensorProduct(1x0e+2x1o x 1x0e+2x1o -> 1x0e | 5 paths | 5 weights)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    ((0, 1, 1)): E3nnIrrepsMatrixBlock(\n",
       "      (operation): E3nnSimpleEdgeBlock(\n",
       "        (tensor_products): ModuleList(\n",
       "          (0): FullyConnectedTensorProduct(1x0e+2x1o x 1x0e+2x1o -> 2x0e+1x1o | 14 paths | 14 weights)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    ((1, 1, 2)): E3nnIrrepsMatrixBlock(\n",
       "      (operation): E3nnSimpleEdgeBlock(\n",
       "        (tensor_products): ModuleList(\n",
       "          (0): FullyConnectedTensorProduct(1x0e+2x1o x 1x0e+2x1o -> 5x0e+4x1o+1x1e+1x2e | 49 paths | 49 weights)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37097241-45f1-44ef-8c10-afb2095c6229",
   "metadata": {},
   "source": [
    "Try to relate this representation with the summary and identify the role of each input in it. For example:\n",
    "\n",
    "- Where is `node_feats_irreps` in this representation?\n",
    "- Why are the output irreps different for each type of block?\n",
    "\n",
    "We encourage you to **play with the three arguments** and see if they have the influence that you expected on the summary and the architecture of the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71013f6-1d14-437c-acf2-1fe80292acaa",
   "metadata": {},
   "source": [
    "We have our model, now we are only missing the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c35007a-0c46-4373-bd35-fae3489b7d7b",
   "metadata": {},
   "source": [
    "Coordinates of a system\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df526f0d-a9b8-4886-8266-7a3b0478786a",
   "metadata": {},
   "source": [
    "Let's say we have to predict a matrix for three interacting points in space: two **A** points at `[0,0,0]` and `[6, 0, 0]` and a **B** point at `[11, 0, 0]`. \n",
    "\n",
    "Something like: (A)---(B)--(A).\n",
    "\n",
    "First, we create the positions array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e625cfe9-6bc6-48e1-8cec-6fbd4c8ef901",
   "metadata": {},
   "outputs": [],
   "source": [
    "positions = np.array([[0, 0, 0], [6.0, 0, 0], [12.0, 0, 0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b0b0f9-501b-4e6c-a523-6896289153f9",
   "metadata": {},
   "source": [
    "And from it, we will create a `BasisConfiguration`, which apart from **positions** contains information about the **basis**, the **cell** and the **boundaries**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d23242b7-25b6-4bdf-bbd5-7961576b6f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = BasisConfiguration(\n",
    "    point_types=[\"A\", \"B\", \"A\"],\n",
    "    positions=positions,\n",
    "    basis=basis,\n",
    "    cell=np.eye(3) * 100,\n",
    "    pbc=(False, False, False),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41fc346-1869-43b7-a39c-fcad6ace0cad",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "The configuration could also store an associated matrix (e.g. the target matrix), however we are not going to use it for now.\n",
    "\n",
    "</div>\n",
    "\n",
    "Let's see **what this configuration looks like**. We can convert it to a `sisl` geometry and plot it (or you could also plot the points yourself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a2b193f4-040a-4c84-8a75-350b88a4378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 1]\n"
     ]
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alphahull": 0,
         "color": "#EDEADE",
         "hovertemplate": "%{meta.position}",
         "legendgroup": "Atoms",
         "meta": {
          "meta": {
           "Atoms_i": 0
          },
          "position": "(0.00, 0.00, 0.00)"
         },
         "name": "Atoms",
         "opacity": 1,
         "showlegend": true,
         "showscale": false,
         "type": "mesh3d",
         "x": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgkUC45B7zD/huJZTeanJPz/dfo43wsE/ehylsRpaqT93HKWxGlqpvz7dfo43wsG/4biWU3mpyb+CRQLjkHvMv+G4llN5qcm/QN1+jjfCwb9/HKWxGlqpv3McpbEaWqk/Pd1+jjfCwT/huJZTeanJP4JFAuOQe8w/watxTcDE2z9L3gV1wwTZP4kToN47UNE/eSxMQWK3uD91LExBYre4v4gToN47UNG/St4FdcME2b/Bq3FNwMTbv0veBXXDBNm/ihOg3jtQ0b99LExBYre4v3IsTEFit7g/hxOg3jtQ0T9K3gV1wwTZP8GrcU3AxNs/0e2L4qDz4z/o9kVx0PnhP6BuP8cb4dg/P91+jjfCwT893X6ON8LBv55uP8cb4di/6PZFcdD54b/R7YvioPPjv+j2RXHQ+eG/oW4/xxvh2L9D3X6ON8LBvzrdfo43wsE/nW4/xxvh2D/o9kVx0PnhP9Hti+Kg8+M/S94FdcME6T+l3wgWformP2rpWAWcMt8/1hCanMZExj/TEJqcxkTGv2jpWAWcMt+/pN8IFn6K5r9L3gV1wwTpv6XfCBZ+iua/a+lYBZwy37/aEJqcxkTGv9AQmpzGRMY/Z+lYBZwy3z+k3wgWformP0veBXXDBOk/cVzLqbzU7D/p9kVx0PnpP+n2RXHQ+eE/47iWU3mpyT/guJZTeanJv+j2RXHQ+eG/6PZFcdD56b9xXMupvNTsv+n2RXHQ+em/6vZFcdD54b/ouJZTeanJv9y4llN5qck/6PZFcdD54T/o9kVx0PnpP3Fcy6m81Ow/aelYBZwy7z/aYy+9rxvsPxZa382Rc+M/w6txTcDEyz+/q3FNwMTLvxVa382Rc+O/2WMvva8b7L9p6VgFnDLvv9pjL72vG+y/F1rfzZFz47/Iq3FNwMTLv7urcU3AxMs/FFrfzZFz4z/ZYy+9rxvsP2npWAWcMu8/AAAAAAAA8D9xXMupvNTsP9Lti+Kg8+M/hEUC45B7zD+ARQLjkHvMv9Hti+Kg8+O/cFzLqbzU7L8AAAAAAADwv3Fcy6m81Oy/0+2L4qDz47+JRQLjkHvMv3xFAuOQe8w/0O2L4qDz4z9wXMupvNTsPwAAAAAAAPA/aelYBZwy7z/aYy+9rxvsPxZa382Rc+M/w6txTcDEyz+/q3FNwMTLvxVa382Rc+O/2WMvva8b7L9p6VgFnDLvv9pjL72vG+y/F1rfzZFz47/Iq3FNwMTLv7urcU3AxMs/FFrfzZFz4z/ZYy+9rxvsP2npWAWcMu8/cVzLqbzU7D/p9kVx0PnpP+n2RXHQ+eE/47iWU3mpyT/guJZTeanJv+j2RXHQ+eG/6PZFcdD56b9xXMupvNTsv+n2RXHQ+em/6vZFcdD54b/ouJZTeanJv9y4llN5qck/6PZFcdD54T/o9kVx0PnpP3Fcy6m81Ow/TN4FdcME6T+m3wgWformP2vpWAWcMt8/1xCanMZExj/UEJqcxkTGv2npWAWcMt+/pd8IFn6K5r9M3gV1wwTpv6bfCBZ+iua/belYBZwy37/bEJqcxkTGv9EQmpzGRMY/aOlYBZwy3z+l3wgWformP0zeBXXDBOk/0u2L4qDz4z/p9kVx0PnhP6FuP8cb4dg/QN1+jjfCwT8+3X6ON8LBv6BuP8cb4di/6fZFcdD54b/S7YvioPPjv+n2RXHQ+eG/om4/xxvh2L9D3X6ON8LBvzvdfo43wsE/nm4/xxvh2D/p9kVx0PnhP9Lti+Kg8+M/w6txTcDE2z9N3gV1wwTZP4oToN47UNE/eyxMQWK3uD93LExBYre4v4kToN47UNG/TN4FdcME2b/Dq3FNwMTbv03eBXXDBNm/ixOg3jtQ0b9/LExBYre4v3QsTEFit7g/iBOg3jtQ0T9M3gV1wwTZP8OrcU3AxNs/hkUC45B7zD/luJZTeanJP0Ldfo43wsE/fhylsRpaqT96HKWxGlqpv0Hdfo43wsG/5LiWU3mpyb+GRQLjkHvMv+W4llN5qcm/Qt1+jjfCwb+CHKWxGlqpv3ccpbEaWqk/QN1+jjfCwT/kuJZTeanJP4ZFAuOQe8w/B1wUMyamoTx3jBRvbM2fPJwmMzgKApY8r9jL8A9rfzyq2MvwD2t/vJsmMzgKApa8dowUb2zNn7wHXBQzJqahvHeMFG9szZ+8nSYzOAoClry02MvwD2t/vKbYy/APa388mSYzOAoCljx2jBRvbM2fPAdcFDMmpqE8",
          "dtype": "f8"
         },
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8"
         }
        },
        {
         "alphahull": 0,
         "color": "#D9FFFF",
         "hovertemplate": "%{meta.position}",
         "legendgroup": "Atoms",
         "meta": {
          "meta": {
           "Atoms_i": 1
          },
          "position": "(6.00, 0.00, 0.00)"
         },
         "name": "Atoms",
         "opacity": 1,
         "showlegend": false,
         "showscale": false,
         "type": "mesh3d",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "y": {
          "bdata": "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",
          "dtype": "f8"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8"
         }
        },
        {
         "alphahull": 0,
         "color": "#EDEADE",
         "hovertemplate": "%{meta.position}",
         "legendgroup": "Atoms",
         "meta": {
          "meta": {
           "Atoms_i": 2
          },
          "position": "(12.00, 0.00, 0.00)"
         },
         "name": "Atoms",
         "opacity": 1,
         "showlegend": false,
         "showscale": false,
         "type": "mesh3d",
         "x": {
          "bdata": "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",
          "dtype": "f8"
         },
         "y": {
          "bdata": "AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAB3LExBYre4P9UQmpzGRMY/watxTcDEyz/Bq3FNwMTLP9YQmpzGRMY/eSxMQWK3uD+s2MvwD2t/PHUsTEFit7i/1BCanMZExr/Bq3FNwMTLv8GrcU3AxMu/1hCanMZExr97LExBYre4v6zYy/APa4+8AAAAAAAAAABdJOg6vhjIPxDLCnHYtdU/Mn9MG4US2z8yf0wbhRLbPxHLCnHYtdU/XyToOr4YyD9gdFvpZ6GOPFsk6Dq+GMi/D8sKcdi11b8yf0wbhRLbvzJ/TBuFEtu/EcsKcdi11b9hJOg6vhjIv2B0W+lnoZ68AAAAAAAAAACIE6DeO1DRP2jpWAWcMt8/FVrfzZFz4z8VWt/NkXPjP2npWAWcMt8/iROg3jtQ0T+bJjM4CgKWPIcToN47UNG/Z+lYBZwy378VWt/NkXPjvxVa382Rc+O/aelYBZwy37+LE6DeO1DRv5smMzgKAqa8AAAAAAAAAAAQywpx2LXVP7BIYBxyj+M/IaUrxi5k6D8hpSvGLmToP7FIYBxyj+M/EssKcdi11T/gk2PT3JibPA/LCnHYtdW/r0hgHHKP478hpSvGLmTovyGlK8YuZOi/sUhgHHKP478Tywpx2LXVv+CTY9PcmKu8AAAAAAAAAABL3gV1wwTZP6XfCBZ+iuY/2mMvva8b7D/aYy+9rxvsP6bfCBZ+iuY/Td4FdcME2T93jBRvbM2fPEneBXXDBNm/pN8IFn6K5r/aYy+9rxvsv9pjL72vG+y/pt8IFn6K5r9P3gV1wwTZv3eMFG9sza+8AAAAAAAAAAAyf0wbhRLbPyGlK8YuZOg/Oa7lVF5q7j85ruVUXmruPyKlK8YuZOg/NH9MG4US2z+XwRiq3jShPDB/TBuFEtu/IKUrxi5k6L85ruVUXmruvzmu5VReau6/IqUrxi5k6L82f0wbhRLbv5fBGKreNLG8AAAAAAAAAADBq3FNwMTbP0veBXXDBOk/aelYBZwy7z9p6VgFnDLvP0zeBXXDBOk/w6txTcDE2z8HXBQzJqahPL+rcU3AxNu/St4FdcME6b9p6VgFnDLvv2npWAWcMu+/TN4FdcME6b/Fq3FNwMTbvwdcFDMmprG8AAAAAAAAAAAyf0wbhRLbPyGlK8YuZOg/Oa7lVF5q7j85ruVUXmruPyKlK8YuZOg/NH9MG4US2z+XwRiq3jShPDB/TBuFEtu/IKUrxi5k6L85ruVUXmruvzmu5VReau6/IqUrxi5k6L82f0wbhRLbv5fBGKreNLG8AAAAAAAAAABL3gV1wwTZP6XfCBZ+iuY/2mMvva8b7D/aYy+9rxvsP6bfCBZ+iuY/Td4FdcME2T93jBRvbM2fPEneBXXDBNm/pN8IFn6K5r/aYy+9rxvsv9pjL72vG+y/pt8IFn6K5r9P3gV1wwTZv3eMFG9sza+8AAAAAAAAAAARywpx2LXVP7FIYBxyj+M/IqUrxi5k6D8ipSvGLmToP7JIYBxyj+M/E8sKcdi11T/hk2PT3JibPA/LCnHYtdW/sEhgHHKP478ipSvGLmTovyKlK8YuZOi/skhgHHKP478Uywpx2LXVv+GTY9PcmKu8AAAAAAAAAACJE6DeO1DRP2rpWAWcMt8/FlrfzZFz4z8WWt/NkXPjP2vpWAWcMt8/ihOg3jtQ0T+cJjM4CgKWPIgToN47UNG/aOlYBZwy378WWt/NkXPjvxZa382Rc+O/a+lYBZwy37+LE6DeO1DRv5wmMzgKAqa8AAAAAAAAAABfJOg6vhjIPxLLCnHYtdU/NH9MG4US2z80f0wbhRLbPxPLCnHYtdU/YSToOr4YyD9idFvpZ6GOPF0k6Dq+GMi/EcsKcdi11b80f0wbhRLbvzR/TBuFEtu/E8sKcdi11b9iJOg6vhjIv2J0W+lnoZ68AAAAAAAAAAB6LExBYre4P9gQmpzGRMY/xatxTcDEyz/Fq3FNwMTLP9kQmpzGRMY/fCxMQWK3uD+x2MvwD2t/PHksTEFit7i/1xCanMZExr/Fq3FNwMTLv8WrcU3AxMu/2RCanMZExr9+LExBYre4v7HYy/APa4+8AAAAAAAAAABgdFvpZ6GOPOCTY9PcmJs8l8EYqt40oTyXwRiq3jShPOGTY9PcmJs8YnRb6WehjjxIXYqFzndTOV10W+lnoY683pNj09yYm7yXwRiq3jShvJfBGKreNKG84ZNj09yYm7xkdFvpZ6GOvEhdioXOd2O5",
          "dtype": "f8"
         },
         "z": {
          "bdata": "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",
          "dtype": "f8"
         }
        }
       ],
       "layout": {
        "scene": {
         "aspectmode": "data",
         "xaxis": {
          "title": {
           "text": "X axis [Ang]"
          }
         },
         "yaxis": {
          "title": {
           "text": "Y axis [Ang]"
          }
         },
         "zaxis": {
          "title": {
           "text": "Z axis [Ang]"
          }
         }
        },
        "template": {
         "layout": {
          "hovermode": "closest",
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "scene": {
           "xaxis": {
            "color": "black",
            "gridcolor": "#ccc",
            "gridwidth": 1,
            "linewidth": 1,
            "mirror": true,
            "showgrid": false,
            "showline": true,
            "ticklen": 5,
            "ticks": "outside",
            "ticksuffix": " ",
            "visible": true,
            "zeroline": false,
            "zerolinecolor": "#ccc",
            "zerolinewidth": 1
           },
           "yaxis": {
            "color": "black",
            "gridcolor": "#ccc",
            "gridwidth": 1,
            "linewidth": 1,
            "mirror": true,
            "showgrid": false,
            "showline": true,
            "ticklen": 5,
            "ticks": "outside",
            "ticksuffix": " ",
            "visible": true,
            "zeroline": false,
            "zerolinecolor": "#ccc",
            "zerolinewidth": 1
           },
           "zaxis": {
            "color": "black",
            "gridcolor": "#ccc",
            "gridwidth": 1,
            "linewidth": 1,
            "mirror": true,
            "showgrid": false,
            "showline": true,
            "ticklen": 5,
            "ticks": "outside",
            "ticksuffix": " ",
            "visible": true,
            "zeroline": false,
            "zerolinecolor": "#ccc",
            "zerolinewidth": 1
           }
          },
          "xaxis": {
           "color": "black",
           "gridcolor": "#ccc",
           "gridwidth": 1,
           "linewidth": 1,
           "mirror": true,
           "showgrid": false,
           "showline": true,
           "ticklen": 5,
           "ticks": "outside",
           "ticksuffix": " ",
           "visible": true,
           "zeroline": false,
           "zerolinecolor": "#ccc",
           "zerolinewidth": 1
          },
          "yaxis": {
           "color": "black",
           "gridcolor": "#ccc",
           "gridwidth": 1,
           "linewidth": 1,
           "mirror": true,
           "showgrid": false,
           "showline": true,
           "ticklen": 5,
           "ticks": "outside",
           "ticksuffix": " ",
           "visible": true,
           "zeroline": false,
           "zerolinecolor": "#ccc",
           "zerolinewidth": 1
          }
         }
        },
        "xaxis": {
         "scaleanchor": "y",
         "scaleratio": 1,
         "title": {
          "text": "X axis [Ang]"
         }
        },
        "yaxis": {
         "title": {
          "text": "Y axis [Ang]"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "geometry = config.to_sisl_geometry()\n",
    "print(geometry.atoms.Z)\n",
    "geometry.plot(show_cell=False, atoms_style={\"size\": geometry.maxR(all=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030f0b7c-4011-4c67-8932-6cd00f20c4c1",
   "metadata": {},
   "source": [
    "In **<span style=\"color:gray\"> gray you can see B atoms </span>** and in **<span style=\"color:lightblue\"> blue you can see the A atom </span>**. Their **sizes are set according to their ranges**, so you can see which points overlap with which. This will become important when we interpret the matrix!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c733703-8fc4-497f-b861-601b188e0890",
   "metadata": {},
   "source": [
    "Preprocessing the data\n",
    "-------------------\n",
    "\n",
    "Now, we need to preprocess the data to make it digestible by our matrix-generating function.  \n",
    "\n",
    "For that, we initialize a `MatrixDataProcessor` that will take care of all the processing. \n",
    "This object contains all the information to correctly process the data, and it exists to make\n",
    "sure that all the processing is consistent (you don't need to store all the different parameters\n",
    "separately, which avoids mistakes when using data processing routines). It needs:\n",
    "\n",
    "- A **basis table** (`BasisTableWithEdges`), which determines all the node and edge types that are possible to find given our basis. It also knows the size of the blocks, and other type dependent variables.\n",
    "- Some **information about the matrix**, which will be used to appropiately pre and postprocess matrices.\n",
    "\n",
    "First let's create the basis table and check that it contains all the information about the basis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "334346b0-201d-4796-86a7-f8cb43e2e9f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tbody><tr><th>Index</th><th>Type</th><th>Irreps</th><th>Max R</th></tr><tr><td>0</td><td>A</td><td>1x0e</td><td>-1</td></tr><tr><td>1</td><td>B</td><td>2x0e + 1x1o</td><td>-1</td></tr></tbody></table>"
      ],
      "text/plain": [
       "BasisTableWithEdges(spherical, basis=[PointBasis(type='A', R=-1, basis=((1, 0, 1),), basis_convention='spherical'), PointBasis(type='B', R=-1, basis=((2, 0, 1), (1, 1, -1)), basis_convention='spherical')])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the basis table.\n",
    "table = BasisTableWithEdges(basis)\n",
    "\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c030ce-545b-4277-aebd-6e145b65cb99",
   "metadata": {},
   "source": [
    "Then we can create the processor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1131f000-a654-4649-9780-f7d3edbb865b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the processor.\n",
    "processor = MatrixDataProcessor(\n",
    "    basis_table=table, symmetric_matrix=True, sub_point_matrix=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a36e98-77f0-4c34-a52a-ed9cbea827d9",
   "metadata": {},
   "source": [
    "Armed with a processor and the data we need to process, we can already initialize a `TorchBasisMatrixData` object, which will parse and **store all the data already in the shape that the torch module expects it**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49ab30f7-ec58-4527-a202-9c2534cb2eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TorchBasisMatrixData(\n",
       "  edge_index=[2, 0],\n",
       "  num_nodes=3,\n",
       "  neigh_isc=[0],\n",
       "  n_edges=0,\n",
       "  positions=[3, 3],\n",
       "  shifts=[0, 3],\n",
       "  cell=[3, 3],\n",
       "  nsc=[1, 3],\n",
       "  node_attrs=[3, 2],\n",
       "  point_types=[3],\n",
       "  edge_types=[0],\n",
       "  metadata={ data_processor=MatrixDataProcessor(basis_table=BasisTableWithEdges(spherical, basis=[PointBasis(type='A', R=-1, basis=((1, 0, 1),), basis_convention='spherical'), PointBasis(type='B', R=-1, basis=((2, 0, 1), (1, 1, -1)), basis_convention='spherical')]), symmetric_matrix=True, sub_point_matrix=False, out_matrix=None, node_attr_getters=[]) }\n",
       ")"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = TorchBasisMatrixData.from_config(config, processor)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0e5c64-7a23-4a75-bd5c-9ec0392d635e",
   "metadata": {},
   "source": [
    "This `TorchBasisMatrixData` is just an extension of `torch_geometric`'s `Data`.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "We can batch several configurations, but in this notebook our objective is simply to compute a matrix for one configuration.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b50a65-cac6-4741-8004-cff41dd0a141",
   "metadata": {},
   "source": [
    "Executing the module\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68860c49-f342-4d76-b12d-3bcb5befb799",
   "metadata": {},
   "source": [
    "The information of the system is now prepared to be passed to the function!\n",
    "\n",
    "We are only **missing a very important thing, the input!**\n",
    "\n",
    "Remember that we specified the input of our function to be of shape `o3.Irreps(0e + 1o)`. Therefore, we need an **input** that is **one scalar and one vector for each node**.\n",
    "\n",
    "This could be anything really. To keep it simple, we will create a \"fake\" function that computes some environment represenation and use it. \n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "In practice, you would use a function that computes a true environment representation. If that representation is equivariant, the\n",
    "symmetry constraints will be automatically satisfied.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106e434-d65a-498b-add4-5726edcf4b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_environment_representation(data, irreps):\n",
    "    \"\"\"Function that mocks a true calculation of an environment representation.\n",
    "\n",
    "    Computes a random array and then ensures that the numbers obey our particular\n",
    "    system's symmetries.\n",
    "    \"\"\"\n",
    "\n",
    "    node_features = irreps.randn(data.num_nodes, -1)\n",
    "    # The point in the middle sees the same in -X and +X directions\n",
    "    # therefore its representation must be 0.\n",
    "    # In principle the +/- YZ are also equivalent, but let's say that there\n",
    "    # is something breaking the symmetry to make the numbers more interesting.\n",
    "    # Note that the spherical harmonics convention is YZX.\n",
    "    node_features[1, 3] = 0\n",
    "    # We make both A points have equivalent features except in the X direction,\n",
    "    # where the features are opposite\n",
    "    node_features[-1, :3] = node_features[0, :3]\n",
    "    node_features[-1, 3] = -node_features[0, 3]\n",
    "    return node_features\n",
    "\n",
    "\n",
    "# Get the environment representation.\n",
    "node_inputs = get_environment_representation(data, node_feats_irreps)\n",
    "node_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c6709e-f238-4518-b7ec-309d80ba5583",
   "metadata": {},
   "source": [
    "And now we can call the function to get a matrix!\n",
    "\n",
    "The function needs two things:\n",
    "\n",
    "- **The structural description of the graph**. This is stored already in our `TorchBasisMatrixData` object, which we have under the `data` variable. \n",
    "- **The computed node features**. We have that under the `node_inputs` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17732c24-b382-47c0-9352-c568491b4ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_labels, edge_labels = model(data, node_feats=node_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae844683-7054-433b-961f-5d0d1fa9d783",
   "metadata": {},
   "source": [
    "Let's see what we received as output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5701d404-31bf-444d-873e-79010e51c973",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NODE LABELS: \", node_labels)\n",
    "print(\"EDGE LABELS:\", edge_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7581b667-6c7d-47d1-b290-980b6ca3abab",
   "metadata": {},
   "source": [
    "**We expected our model to produce a matrix, and instead we get two flat arrays!**\n",
    "\n",
    " <img src=\"https://media4.giphy.com/media/FcuiZUneg1YRAu1lH2/giphy.gif?cid=ecf05e47l8oqq4sufybs72lu8jzvu1ow32m1fiqrc24lhgj8&ep=v1_gifs_search&rid=giphy.gif&ct=g\" alt=\"confused\" width=\"200\"/>\n",
    "\n",
    "Don't worry, **it's just a different representation of the matrix** that is much more convenient for the function to compute. When training a model using this function, it is possible that you don't actually need to convert this to a \"real\" matrix. That's why the arrays are returned like this.\n",
    "\n",
    "In our particular case, however, we are on a mission to get the matrix, so **we need to do some simple post processing**.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note\n",
    "\n",
    "These tensors have been computed with pytorch operations, so they keep track of the operations performed. Therefore, **gradients can be computed** either from these tensors or from further tensors that you compute with them. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0a3ce49-4b6e-4b83-9f44-5c6beef5f7a4",
   "metadata": {},
   "source": [
    "Post processing\n",
    "---------------\n",
    "\n",
    "This step is simple. Remember we created a `MatrixDataProcessor`? It's time to put it to use!\n",
    "\n",
    "The processor has a `matrix_from_data` method that given:\n",
    "\n",
    "- The **information of the configuration**, in the form of the preprocessed `TorchBasisMatrixData` object.\n",
    "- The **output of the function** to the `predictions` argument.\n",
    "\n",
    "will return the actual **sparse** matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e37d45-3687-4bff-bc5d-0f712c31c515",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = processor.matrix_from_data(\n",
    "    data,\n",
    "    predictions={\"node_labels\": node_labels, \"edge_labels\": edge_labels},\n",
    ")\n",
    "matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b5b475a-b55e-4e29-b212-ec54e9f6a614",
   "metadata": {},
   "source": [
    "This is a `scipy` sparse matrix. If you are not familiar with sparse matrices, they are just an efficient way of storing matrices with many zeros.\n",
    "\n",
    "You can also specify the `out_format` argument to for any other supported output format (see the `graph2mat.Formats` documentation for all the supported formats). For example, you can ask for a torch tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa794cc-0317-4766-9234-e0303dc90c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.matrix_from_data(\n",
    "    data,\n",
    "    predictions={\"node_labels\": node_labels, \"edge_labels\": edge_labels},\n",
    "    out_format=\"torch\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4a990-1cbb-4188-8035-ac3ca222709b",
   "metadata": {},
   "source": [
    "And we also provide `plot_basis_matrix`, a nice tool to quickly visualize the matrix and understand what you got."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb65835b-b2c6-4b18-adaf-ffd3c4b68f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from graph2mat.tools.viz import plot_basis_matrix\n",
    "\n",
    "plot_basis_matrix(\n",
    "    matrix,\n",
    "    config,\n",
    "    point_lines={\"color\": \"black\"},\n",
    "    basis_lines={\"color\": \"blue\"},\n",
    "    colorscale=\"temps\",\n",
    "    text=\".3f\",\n",
    "    basis_labels=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e777f505-21a6-4719-a225-28b5621ffeb5",
   "metadata": {},
   "source": [
    "The black lines delimit blocks of the matrix that correspond to the same point-point interaction, and the blue dashed lines delimit the blocks of interaction between sets of basis functions.\n",
    "\n",
    "The rows and columns are labeled as $P: (l, m)$ where $P$ is the index of the point and $l$, $m$ are the indices of the spherical harmonics.\n",
    "\n",
    "There are some important things to note:\n",
    "\n",
    "- **There are two white squares**. These correspond to values of the matrix that were not set. Which points are interacting for those elements? Does it make sense that we have a blank space there then?\n",
    "- Look at the **interactions between points 0 and 1 and compare them to those between points 1 and 2**. How similar are they? Does it make sense?\n",
    "- From the previous point, you will conclude that the reason there's something special is because the structure is symmetric. Try to move then the third point (change its position) to see if something changes. You will see that nothing changes. This is because we have used `E3nnGraph2Mat` with its simplest settings, its defaults (block operations `E3nnSimpleNodeBlock` and `E3nnSimpleEdgeBlock`). It simply **trusts that the inputs contain all the important information** and combines them to generate the matrix. More complex block operations that use edge distances, directions, etc... can be used within `E3nnGraph2Mat`, see its documentation to understand how.\n",
    "- As a conclusion from the previous point, we can extract that **if we change the inputs, that should induce changes in the matrix**. Try to change our fake `get_environment_representation` function, keeping in mind that the first number is a scalar and the other three a vector. Maybe **try to rotate the vector** and see what happens. You will discover that `E3nnGraph2Mat` **is an equivariant function**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a68253e-c6aa-423e-8625-0390f65c606e",
   "metadata": {},
   "source": [
    "Summary and next steps\n",
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796c73fc-93cf-41cf-8ba9-73c4f646bffd",
   "metadata": {},
   "source": [
    "In this notebook we learned the whole process to go **from the coordinates** of some points in space **to an equivariant matrix**.\n",
    "\n",
    "The **next steps** could be:\n",
    "\n",
    "- Understanding how to compute multiple matrices with the same function call (**batching**). See [this notebook](./Batching.ipynb).\n",
    "- Understanding how to **train the function** to produce the target matrix. See [this notebook](<./Fitting matrices.ipynb>)\n",
    "- Combining this function with other modules for your particular application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43feaaa3-11e9-494f-96de-7f21e9a4d02a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph2mat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
