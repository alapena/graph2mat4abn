{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f7a4e4a8",
   "metadata": {},
   "source": [
    "This script only works with the last models I trained (e.g. h_crystalls_15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464ce8e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/alapena/GitHub/graph2mat4abn')\n",
    "import os\n",
    "os.chdir('/home/ICN2/alapena/GitHub/graph2mat4abn') # Change to the root directory of the project\n",
    "\n",
    "from graph2mat4abn.tools.import_utils import load_config, get_object_from_module\n",
    "from graph2mat4abn.tools.tools import get_basis_from_structures_paths, get_kwargs, load_model\n",
    "from graph2mat4abn.tools.scripts_utils import get_model_dataset, init_mace_g2m_model\n",
    "from graph2mat4abn.tools.script_plots import update_loss_plots, plot_grad_norms\n",
    "from pathlib import Path\n",
    "from e3nn import o3\n",
    "from mace.modules import MACE, RealAgnosticResidualInteractionBlock\n",
    "from graph2mat.models import MatrixMACE\n",
    "from graph2mat.bindings.e3nn import E3nnGraph2Mat\n",
    "import torch\n",
    "import warnings\n",
    "from graph2mat import BasisTableWithEdges\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"The TorchScript type system doesn't support\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*is not a known matrix type key.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bace8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The current model:\n",
    "model_dir = Path(\"results/block_type_mse_nonzero_globalsquarenorm_1e-3_2-8ATOMS\")\n",
    "filename = \"train_best_model.tar\"\n",
    "config = load_config(model_dir / \"config.yaml\")\n",
    "\n",
    "# Basis generation (needed to initialize the model)\n",
    "train_paths, val_paths = get_model_dataset(model_dir, verbose=False)\n",
    "paths = train_paths + val_paths\n",
    "basis = get_basis_from_structures_paths(paths, verbose=True, num_unique_z=config[\"dataset\"].get(\"num_unique_z\", None))\n",
    "table = BasisTableWithEdges(basis)\n",
    "\n",
    "print(\"Initializing model...\")\n",
    "model, optimizer, lr_scheduler, loss_fn = init_mace_g2m_model(config, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0091df55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "model_path = model_dir / filename\n",
    "model, checkpoint, optimizer, lr_scheduler = load_model(model, optimizer, model_path, lr_scheduler=None, initial_lr=None, device='cpu')\n",
    "history = checkpoint[\"history\"]\n",
    "print(f\"Loaded model in epoch {checkpoint[\"epoch\"]} with training loss {checkpoint[\"train_loss\"]} and validation loss {checkpoint[\"val_loss\"]}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7227bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(history[\"epoch_times\"]) / 60 / 60 / 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdeb3bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    ".1923520622733568*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad9f58",
   "metadata": {},
   "outputs": [],
   "source": [
    ".616449494560563*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f2d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    ".98696967363378*60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59777db6",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5da00a1",
   "metadata": {},
   "source": [
    "## Loss curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d05ff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "def update_loss_plots(history, verbose=False):\n",
    "    def detach_list(tensor_list):\n",
    "        return [\n",
    "            t.detach().item() if isinstance(t, torch.Tensor)\n",
    "            else t if t is None\n",
    "            else float(t)\n",
    "            for t in tensor_list\n",
    "        ]\n",
    "    \n",
    "    # Prepare data\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        np.array([\n",
    "            detach_list(history[\"train_loss\"]),\n",
    "            detach_list(history[\"val_loss\"]),\n",
    "            detach_list(history[\"train_edge_loss\"]),\n",
    "            detach_list(history[\"val_edge_loss\"]),\n",
    "            detach_list(history[\"train_node_loss\"]),\n",
    "            detach_list(history[\"val_node_loss\"]),\n",
    "            detach_list(history[\"learning_rate\"]),\n",
    "        ]).T,\n",
    "        columns=[\"Train total\", \"Val total\", \"Train edge\", \"Val edge\", \"Train node\", \"Val node\", \"Learning rate\"],\n",
    "    )\n",
    "    \n",
    "\n",
    "    # Create figure with secondary y-axis\n",
    "    fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "    \n",
    "    # Add loss traces (primary y-axis)\n",
    "    loss_colors = {\n",
    "        \"Train total\": \"blue\",\n",
    "        \"Val total\": \"red\",\n",
    "        \"Val_extra total\": \"magenta\",\n",
    "        \"Train edge\": \"blue\",\n",
    "        \"Val edge\": \"red\",\n",
    "        \"Val_extra edge\": \"magenta\",\n",
    "        \"Train node\": \"blue\",\n",
    "        \"Val node\": \"red\",\n",
    "        \"Val_extra node\": \"magenta\",\n",
    "    }\n",
    "    loss_dashes = {\n",
    "        \"Train total\": \"solid\",\n",
    "        \"Val total\": \"solid\",\n",
    "        \"Val_extra total\": \"solid\",\n",
    "        \"Train edge\": \"dash\",\n",
    "        \"Val edge\": \"dash\",\n",
    "        \"Val_extra edge\": \"dash\",\n",
    "        \"Train node\": \"dot\",\n",
    "        \"Val node\": \"dot\",\n",
    "        \"Val_extra node\": \"dot\"\n",
    "    }\n",
    "    \n",
    "    for col in df.columns[:-1]:  # All columns except Learning rate\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=df.index,\n",
    "                y=df[col],\n",
    "                name=col,\n",
    "                line=dict(color=loss_colors[col], dash=loss_dashes[col]),\n",
    "                legendgroup=col.split()[1] if col.split()[0] in [\"Train\", \"Val\"] else col,\n",
    "                connectgaps=True\n",
    "            ),\n",
    "            secondary_y=False\n",
    "        )\n",
    "    \n",
    "    # Add learning rate trace (secondary y-axis)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df.index,\n",
    "            y=df[\"Learning rate\"],\n",
    "            name=\"Learning rate\",\n",
    "            line=dict(color=\"lightgreen\", dash=\"solid\"),\n",
    "            legendgroup=\"Learning rate\"\n",
    "        ),\n",
    "        secondary_y=True\n",
    "    )\n",
    "    \n",
    "    # Set axis titles and layout\n",
    "    loss_values = df.drop(columns=[\"Learning rate\"]).to_numpy().flatten()\n",
    "    loss_values = [v for v in loss_values if v is not None]\n",
    "\n",
    "    ylim_up = int(np.percentile(loss_values, 95)) + 10\n",
    "    fig.update_layout(\n",
    "        title=f\"Loss curves\",\n",
    "        xaxis_title=\"Epoch number\",\n",
    "        yaxis=dict(\n",
    "            title=\"Loss (eVÂ²)\",\n",
    "            showgrid=True,\n",
    "            # type=\"log\",\n",
    "            range=[-5, ylim_up]\n",
    "        ),\n",
    "        yaxis2=dict(\n",
    "            title=\"Learning rate\",\n",
    "            showgrid=False,\n",
    "            type=\"log\",\n",
    "            side=\"right\",\n",
    "            tickformat=\".0e\", \n",
    "            dtick=1,\n",
    "        ),\n",
    "        grid=dict(xside=\"bottom\", yside=\"left\"),\n",
    "        legend=dict(\n",
    "            x=1.1,  \n",
    "            xanchor=\"left\",  \n",
    "            y=1.0,  \n",
    "            yanchor=\"top\"  \n",
    "        ),\n",
    "        margin=dict(r=150)\n",
    "    )\n",
    "    return fig\n",
    "\n",
    "update_loss_plots(history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c482cf8b",
   "metadata": {},
   "source": [
    "## Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a7d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_grad_norms(history['grad_norms'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c820abf6",
   "metadata": {},
   "source": [
    "Good! It does not seem that there is any vanishing gradients problem. All the gradients remainet ~ctt during the training, and the model is still learning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f70916d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph2mat_upt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
