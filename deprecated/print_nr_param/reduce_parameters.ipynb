{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb1fc347",
   "metadata": {},
   "source": [
    "In this nb we will try to reduce the number of parameters of our model. Currently, the model overfits heavily on nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47138d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/home/alapena/GitHub/graph2mat4abn')\n",
    "import os\n",
    "os.chdir('/home/ICN2/alapena/GitHub/graph2mat4abn') # Change to the root directory of the project\n",
    "\n",
    "from graph2mat4abn.tools.import_utils import load_config, get_object_from_module\n",
    "from graph2mat4abn.tools.tools import get_basis_from_structures_paths, get_kwargs\n",
    "from graph2mat4abn.tools.scripts_utils import get_model_dataset\n",
    "from pathlib import Path\n",
    "from e3nn import o3\n",
    "from mace.modules import MACE, RealAgnosticResidualInteractionBlock\n",
    "from graph2mat.models import MatrixMACE\n",
    "from graph2mat.bindings.e3nn import E3nnGraph2Mat\n",
    "import torch\n",
    "import warnings\n",
    "from graph2mat import BasisTableWithEdges\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", message=\"The TorchScript type system doesn't support\")\n",
    "warnings.filterwarnings(\"ignore\", message=\".*is not a known matrix type key.*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7667db41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Basis computation.\n",
      "Number of structures to look on: 399\n",
      "Looking for unique atoms in each structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 72.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found enough basis points. Breaking the search...\n",
      "Found enough basis points. Breaking the search...\n",
      "Found the following atomic numbers: [7, 5]\n",
      "Corresponding path indices: [0, 0]\n",
      "Basis with 2 elements built!\n",
      "\n",
      "Basis for atom 0.\n",
      "\tAtom type: 5\n",
      "\tBasis: ((2, 0, 1), (2, 1, -1), (1, 2, 1))\n",
      "\tBasis convention: siesta_spherical\n",
      "\tR: [3.02420918 2.02341372 3.73961942 3.73961942 3.73961942 2.51253945\n",
      " 2.51253945 2.51253945 3.73961942 3.73961942 3.73961942 3.73961942\n",
      " 3.73961942]\n",
      "\n",
      "Basis for atom 1.\n",
      "\tAtom type: 7\n",
      "\tBasis: ((2, 0, 1), (2, 1, -1), (1, 2, 1))\n",
      "\tBasis convention: siesta_spherical\n",
      "\tR: [2.25704422 1.4271749  2.78012609 2.78012609 2.78012609 1.75309697\n",
      " 1.75309697 1.75309697 2.78012609 2.78012609 2.78012609 2.78012609\n",
      " 2.78012609]\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ICN2/alapena/miniconda3/envs/graph2mat_upt/lib/python3.12/site-packages/mace/modules/blocks.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(atomic_energies, dtype=torch.get_default_dtype()),\n"
     ]
    }
   ],
   "source": [
    "# The current model:\n",
    "model_dir = Path(\"results/h_crystalls_11\")\n",
    "config = load_config(model_dir / \"config.yaml\")\n",
    "\n",
    "# Basis generation (needed to initialize the model)\n",
    "train_paths, val_paths = get_model_dataset(model_dir, verbose=False)\n",
    "paths = train_paths + val_paths\n",
    "basis = get_basis_from_structures_paths(paths, verbose=True, num_unique_z=config[\"dataset\"].get(\"num_unique_z\", None))\n",
    "table = BasisTableWithEdges(basis)\n",
    "\n",
    "print(\"Initializing model...\")\n",
    "# === Enviroment descriptor initialization ===\n",
    "env_config = config[\"environment_representation\"]\n",
    "\n",
    "num_interactions = env_config[\"num_interactions\"]\n",
    "hidden_irreps = o3.Irreps(env_config[\"hidden_irreps\"])\n",
    "\n",
    "# ! This operation is somehow time-consuming:\n",
    "mace_descriptor = MACE(\n",
    "    r_max=env_config[\"r_max\"],\n",
    "    num_bessel=env_config[\"num_bessel\"],\n",
    "    num_polynomial_cutoff=env_config[\"num_polynomial_cutoff\"],\n",
    "    max_ell=env_config[\"max_ell\"],\n",
    "    interaction_cls=RealAgnosticResidualInteractionBlock,\n",
    "    interaction_cls_first=RealAgnosticResidualInteractionBlock,\n",
    "    num_interactions=num_interactions,\n",
    "    num_elements=env_config[\"num_elements\"],\n",
    "    hidden_irreps=hidden_irreps,\n",
    "    MLP_irreps=o3.Irreps(env_config[\"MLP_irreps\"]),\n",
    "    atomic_energies=torch.tensor(env_config[\"atomic_energies\"]),\n",
    "    avg_num_neighbors=env_config[\"avg_num_neighbors\"],\n",
    "    atomic_numbers=env_config[\"atomic_numbers\"],\n",
    "    correlation=env_config[\"correlation\"],\n",
    "    gate=get_object_from_module(env_config[\"gate\"], \"torch.nn.functional\"),\n",
    ")\n",
    "\n",
    "# === Model initialization ===\n",
    "model_config = config[\"model\"]\n",
    "\n",
    "# === Glue between MACE and E3nnGraph2Mat init ===\n",
    "model = MatrixMACE(\n",
    "    mace = mace_descriptor,\n",
    "    readout_per_interaction=model_config.get(\"readout_per_interaction\", False),\n",
    "    graph2mat_cls = E3nnGraph2Mat,\n",
    "    \n",
    "    # Readout-specific arguments\n",
    "    unique_basis = table,\n",
    "    symmetric = True,\n",
    "\n",
    "    # Preprocessing\n",
    "    preprocessing_edges = get_object_from_module(\n",
    "        model_config[\"preprocessing_edges\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    preprocessing_edges_kwargs = get_kwargs(model_config[\"preprocessing_edges\"], config),\n",
    "\n",
    "    preprocessing_nodes = get_object_from_module(\n",
    "        model_config[\"preprocessing_nodes\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    preprocessing_nodes_kwargs = get_kwargs(model_config[\"preprocessing_nodes\"], config),\n",
    "\n",
    "    # Operations\n",
    "    node_operation = get_object_from_module(\n",
    "        model_config[\"node_operation\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    node_operation_kwargs = get_kwargs(model_config[\"node_operation\"], config),\n",
    "\n",
    "    edge_operation = get_object_from_module(\n",
    "        model_config[\"edge_operation\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    edge_operation_kwargs = get_kwargs(model_config[\"edge_operation\"], config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "278c6837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Params: 311098\n",
      "Total Trainable Params: 45114\n",
      "Parameters of G2M: 265984\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model, verbose=True):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad:\n",
    "            continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params += params\n",
    "    if verbose:\n",
    "        print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "p_tot=count_parameters(model, verbose=False)\n",
    "p_mace=count_parameters(mace_descriptor, verbose=False)\n",
    "print(\"Parameters of G2M:\", p_tot-p_mace)\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "455de20f",
   "metadata": {},
   "source": [
    "Most of the params are inside G2M. Let's try to reduce the node's params. Removing the $p_n$ preprocessing function for nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df4a2fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Basis computation.\n",
      "Number of structures to look on: 399\n",
      "Looking for unique atoms in each structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00, 76.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found enough basis points. Breaking the search...\n",
      "Found enough basis points. Breaking the search...\n",
      "Found the following atomic numbers: [7, 5]\n",
      "Corresponding path indices: [0, 0]\n",
      "Basis with 2 elements built!\n",
      "\n",
      "Basis for atom 0.\n",
      "\tAtom type: 5\n",
      "\tBasis: ((2, 0, 1), (2, 1, -1), (1, 2, 1))\n",
      "\tBasis convention: siesta_spherical\n",
      "\tR: [3.02420918 2.02341372 3.73961942 3.73961942 3.73961942 2.51253945\n",
      " 2.51253945 2.51253945 3.73961942 3.73961942 3.73961942 3.73961942\n",
      " 3.73961942]\n",
      "\n",
      "Basis for atom 1.\n",
      "\tAtom type: 7\n",
      "\tBasis: ((2, 0, 1), (2, 1, -1), (1, 2, 1))\n",
      "\tBasis convention: siesta_spherical\n",
      "\tR: [2.25704422 1.4271749  2.78012609 2.78012609 2.78012609 1.75309697\n",
      " 1.75309697 1.75309697 2.78012609 2.78012609 2.78012609 2.78012609\n",
      " 2.78012609]\n",
      "Initializing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/ICN2/alapena/miniconda3/envs/graph2mat_upt/lib/python3.12/site-packages/mace/modules/blocks.py:187: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  torch.tensor(atomic_energies, dtype=torch.get_default_dtype()),\n"
     ]
    }
   ],
   "source": [
    "# The current model:\n",
    "model_dir = Path(\"results/h_crystalls_11\")\n",
    "config = load_config(model_dir / \"config.yaml\")\n",
    "\n",
    "# Basis generation (needed to initialize the model)\n",
    "train_paths, val_paths = get_model_dataset(model_dir, verbose=False)\n",
    "paths = train_paths + val_paths\n",
    "basis = get_basis_from_structures_paths(paths, verbose=True, num_unique_z=config[\"dataset\"].get(\"num_unique_z\", None))\n",
    "table = BasisTableWithEdges(basis)\n",
    "\n",
    "print(\"Initializing model...\")\n",
    "# === Enviroment descriptor initialization ===\n",
    "env_config = config[\"environment_representation\"]\n",
    "\n",
    "num_interactions = env_config[\"num_interactions\"]\n",
    "hidden_irreps = o3.Irreps(env_config[\"hidden_irreps\"])\n",
    "\n",
    "# ! This operation is somehow time-consuming:\n",
    "mace_descriptor = MACE(\n",
    "    r_max=env_config[\"r_max\"],\n",
    "    num_bessel=env_config[\"num_bessel\"],\n",
    "    num_polynomial_cutoff=env_config[\"num_polynomial_cutoff\"],\n",
    "    max_ell=env_config[\"max_ell\"],\n",
    "    interaction_cls=RealAgnosticResidualInteractionBlock,\n",
    "    interaction_cls_first=RealAgnosticResidualInteractionBlock,\n",
    "    num_interactions=num_interactions,\n",
    "    num_elements=env_config[\"num_elements\"],\n",
    "    hidden_irreps=hidden_irreps,\n",
    "    MLP_irreps=o3.Irreps(env_config[\"MLP_irreps\"]),\n",
    "    atomic_energies=torch.tensor(env_config[\"atomic_energies\"]),\n",
    "    avg_num_neighbors=env_config[\"avg_num_neighbors\"],\n",
    "    atomic_numbers=env_config[\"atomic_numbers\"],\n",
    "    correlation=env_config[\"correlation\"],\n",
    "    gate=get_object_from_module(env_config[\"gate\"], \"torch.nn.functional\"),\n",
    ")\n",
    "\n",
    "# === Model initialization ===\n",
    "model_config = config[\"model\"]\n",
    "\n",
    "# === Glue between MACE and E3nnGraph2Mat init ===\n",
    "model_1 = MatrixMACE(\n",
    "    mace = mace_descriptor,\n",
    "    readout_per_interaction=model_config.get(\"readout_per_interaction\", False),\n",
    "    graph2mat_cls = E3nnGraph2Mat,\n",
    "    \n",
    "    # Readout-specific arguments\n",
    "    unique_basis = table,\n",
    "    symmetric = True,\n",
    "\n",
    "    # Preprocessing\n",
    "    preprocessing_edges = get_object_from_module(\n",
    "        model_config[\"preprocessing_edges\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    preprocessing_edges_kwargs = get_kwargs(model_config[\"preprocessing_edges\"], config),\n",
    "\n",
    "    # preprocessing_nodes = get_object_from_module(\n",
    "    #     model_config[\"preprocessing_nodes\"], \n",
    "    #     'graph2mat.bindings.e3nn.modules'\n",
    "    # ),\n",
    "    # preprocessing_nodes_kwargs = get_kwargs(model_config[\"preprocessing_nodes\"], config),\n",
    "\n",
    "    # Operations\n",
    "    node_operation = get_object_from_module(\n",
    "        model_config[\"node_operation\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    node_operation_kwargs = get_kwargs(model_config[\"node_operation\"], config),\n",
    "\n",
    "    edge_operation = get_object_from_module(\n",
    "        model_config[\"edge_operation\"], \n",
    "        'graph2mat.bindings.e3nn.modules'\n",
    "    ),\n",
    "    edge_operation_kwargs = get_kwargs(model_config[\"edge_operation\"], config),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c144dffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Trainable Params: 280766\n",
      "Total Trainable Params: 45114\n",
      "Parameters of G2M: 235652\n",
      "Compared to before: 265984\n"
     ]
    }
   ],
   "source": [
    "p_tot_1=count_parameters(model_1, verbose=False)\n",
    "p_mace=count_parameters(mace_descriptor, verbose=False)\n",
    "print(\"Parameters of G2M:\", p_tot_1-p_mace)\n",
    "print(\"Compared to before:\", p_tot-p_mace)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graph2mat_upt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
